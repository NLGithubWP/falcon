2022/06/03 20:56:09 global-const.go:244: Read user defined env var {IS_DEBUG: debug-off}
2022/06/03 20:56:09 global-const.go:241: Set env var to default {TEST_IMG_NAME: redis:5.0.3-alpine3.8}
2022/06/03 20:56:09 global-const.go:241: Set env var to default {FALCON_WORKER_IMAGE: falcon-dist-train:latest}
2022/06/03 20:56:09 global-const.go:244: Read user defined env var {COORD_SERVER_IP: 127.0.0.1}
2022/06/03 20:56:09 global-const.go:244: Read user defined env var {COORD_SERVER_PORT: 30004}
2022/06/03 20:56:09 global-const.go:244: Read user defined env var {PARTY_SERVER_IP: 127.0.0.1}
2022/06/03 20:56:09 global-const.go:244: Read user defined env var {PARTY_SERVER_NODE_PORT: 30005}
2022/06/03 20:56:09 global-const.go:244: Read user defined env var {PARTY_ID: 0}
2022/06/03 20:56:09 global-const.go:244: Read user defined env var {MPC_EXE_PATH: /opt/falcon/third_party/MP-SPDZ/semi-party.x}
2022/06/03 20:56:09 global-const.go:244: Read user defined env var {FL_ENGINE_PATH: /opt/falcon/build/src/executor/falcon}
2022/06/03 20:56:09 falcon_platform.go:181: common.MpcExecutorPortFileBasePath is /opt/falcon/third_party/MP-SPDZ/Programs/Public-Input/
2022/06/03 20:56:09 global-const.go:244: Read user defined env var {PARTY_SERVER_CLUSTER_IPS: 127.0.0.1}
2022/06/03 20:56:09 global-const.go:244: Read user defined env var {PARTY_SERVER_CLUSTER_LABEL: host}
2022/06/03 20:56:09 falcon_platform.go:196: common.PartyServerClusterIPs is [127.0.0.1]
2022/06/03 20:56:09 falcon_platform.go:197: common.PartyServerClusterIPs is [host]
2022/06/03 20:56:09 falcon_platform.go:359: Launch falcon_platform, Service is  partyserver
2022/06/03 20:56:09 run_partyserver.go:78: RunPartyServer: connecting to Coordinator 127.0.0.1:30004 to AddPort 30005
2022/06/03 20:56:09 run_partyserver.go:81: RunPartyServer: PartyServerAdd  127.0.0.1
2022/06/03 20:56:09 run_partyserver.go:88: [party server 0] listening on IP: 127.0.0.1, Port: 30005
2022/06/03 20:57:25 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30005
2022/06/03 20:57:25 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/03 20:57:25 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/03 20:57:25 controller.go:20: [PartyServer]: PartyServer Schedule worker 1 to node 0 
2022/06/03 20:57:25 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty0-cent-worker1-job1-tr-pred-task-stage
2022/06/03 20:57:25 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609/runtime_logs/pty0-cent-worker1-job1-tr-pred-task-stage
2022/06/03 20:57:25 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/03 20:57:25 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22002, ExecutorExecutorPort is [22003 22004 22005],
2022/06/03 20:57:25 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty0-cent-worker1-job1-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609/runtime_logs/pty0-cent-worker1-job1-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22002 \
--env MASTER_ADDR=127.0.0.1:22001 \
--env WORKER_ID=1 \
--env GROUP_ID=0 \
--env PARTY_ID=0 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/03 20:57:51 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/03 20:57:51 utils.go:198: [ExecuteCmd]: OutPut is  t6fkbpcngey3zmk1tsk2g2rez
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/03 20:57:51 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/03 21:20:28 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30005
2022/06/03 21:20:28 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/03 21:20:28 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/03 21:20:28 controller.go:20: [PartyServer]: PartyServer Schedule worker 2 to node 0 
2022/06/03 21:20:28 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty0-cent-worker2-job2-tr-pred-task-stage
2022/06/03 21:20:28 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609/runtime_logs/pty0-cent-worker2-job2-tr-pred-task-stage
2022/06/03 21:20:28 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/03 21:20:28 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22018, ExecutorExecutorPort is [22019 22020 22021],
2022/06/03 21:20:28 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty0-cent-worker2-job2-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609/runtime_logs/pty0-cent-worker2-job2-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22018 \
--env MASTER_ADDR=127.0.0.1:22017 \
--env WORKER_ID=2 \
--env GROUP_ID=0 \
--env PARTY_ID=0 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/03 21:20:54 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/03 21:20:54 utils.go:198: [ExecuteCmd]: OutPut is  fqnuoxnpd0cdj7zx8yff286si
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/03 21:20:54 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/05 16:01:30 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30005
2022/06/05 16:01:30 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/05 16:01:30 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/05 16:01:30 controller.go:20: [PartyServer]: PartyServer Schedule worker 3 to node 0 
2022/06/05 16:01:30 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty0-cent-worker3-job3-tr-pred-task-stage
2022/06/05 16:01:30 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609/runtime_logs/pty0-cent-worker3-job3-tr-pred-task-stage
2022/06/05 16:01:30 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/05 16:01:30 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22034, ExecutorExecutorPort is [22035 22036 22037],
2022/06/05 16:01:30 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty0-cent-worker3-job3-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609/runtime_logs/pty0-cent-worker3-job3-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22034 \
--env MASTER_ADDR=127.0.0.1:22033 \
--env WORKER_ID=3 \
--env GROUP_ID=0 \
--env PARTY_ID=0 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/05 16:01:56 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/05 16:01:56 utils.go:198: [ExecuteCmd]: OutPut is  l2e2ze4iopdzdtx8br2xrx9ji
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/05 16:01:56 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/05 16:09:00 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30005
2022/06/05 16:09:00 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/05 16:09:00 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/05 16:09:00 controller.go:20: [PartyServer]: PartyServer Schedule worker 4 to node 0 
2022/06/05 16:09:00 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty0-cent-worker4-job4-tr-pred-task-stage
2022/06/05 16:09:00 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609/runtime_logs/pty0-cent-worker4-job4-tr-pred-task-stage
2022/06/05 16:09:00 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/05 16:09:00 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22050, ExecutorExecutorPort is [22051 22052 22053],
2022/06/05 16:09:00 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty0-cent-worker4-job4-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609/runtime_logs/pty0-cent-worker4-job4-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22050 \
--env MASTER_ADDR=127.0.0.1:22049 \
--env WORKER_ID=4 \
--env GROUP_ID=0 \
--env PARTY_ID=0 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/05 16:09:25 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/05 16:09:25 utils.go:198: [ExecuteCmd]: OutPut is  1r9oj37sd2oro33e7fl3w6lp7
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/05 16:09:25 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/05 16:31:48 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30005
2022/06/05 16:31:48 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/05 16:31:48 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/05 16:31:48 controller.go:20: [PartyServer]: PartyServer Schedule worker 5 to node 0 
2022/06/05 16:31:48 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty0-cent-worker5-job5-tr-pred-task-stage
2022/06/05 16:31:48 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609/runtime_logs/pty0-cent-worker5-job5-tr-pred-task-stage
2022/06/05 16:31:48 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/05 16:31:48 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22066, ExecutorExecutorPort is [22067 22068 22069],
2022/06/05 16:31:48 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty0-cent-worker5-job5-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609/runtime_logs/pty0-cent-worker5-job5-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22066 \
--env MASTER_ADDR=127.0.0.1:22065 \
--env WORKER_ID=5 \
--env GROUP_ID=0 \
--env PARTY_ID=0 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/05 16:32:11 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/05 16:32:11 utils.go:198: [ExecuteCmd]: OutPut is  b12c0mh0mheryedn331uxk9wu
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/05 16:32:11 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/05 16:35:19 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30005
2022/06/05 16:35:19 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/05 16:35:19 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/05 16:35:19 controller.go:20: [PartyServer]: PartyServer Schedule worker 6 to node 0 
2022/06/05 16:35:19 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty0-cent-worker6-job6-tr-pred-task-stage
2022/06/05 16:35:19 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609/runtime_logs/pty0-cent-worker6-job6-tr-pred-task-stage
2022/06/05 16:35:19 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/05 16:35:19 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22082, ExecutorExecutorPort is [22083 22084 22085],
2022/06/05 16:35:19 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty0-cent-worker6-job6-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609/runtime_logs/pty0-cent-worker6-job6-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22082 \
--env MASTER_ADDR=127.0.0.1:22081 \
--env WORKER_ID=6 \
--env GROUP_ID=0 \
--env PARTY_ID=0 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/05 16:35:38 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/05 16:35:38 utils.go:198: [ExecuteCmd]: OutPut is  lofilt6omkqp5fcjvia1q2vye
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/05 16:35:38 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/05 16:36:15 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30005
2022/06/05 16:36:15 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/05 16:36:15 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/05 16:36:15 controller.go:20: [PartyServer]: PartyServer Schedule worker 7 to node 0 
2022/06/05 16:36:15 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty0-cent-worker7-job7-tr-pred-task-stage
2022/06/05 16:36:15 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609/runtime_logs/pty0-cent-worker7-job7-tr-pred-task-stage
2022/06/05 16:36:15 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/05 16:36:15 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22098, ExecutorExecutorPort is [22099 22100 22101],
2022/06/05 16:36:15 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty0-cent-worker7-job7-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609/runtime_logs/pty0-cent-worker7-job7-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22098 \
--env MASTER_ADDR=127.0.0.1:22097 \
--env WORKER_ID=7 \
--env GROUP_ID=0 \
--env PARTY_ID=0 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/05 16:36:33 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/05 16:36:33 utils.go:198: [ExecuteCmd]: OutPut is  ha2ancxvxvzauloecry8j0myc
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/05 16:36:33 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/05 16:41:55 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30005
2022/06/05 16:41:55 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/05 16:41:55 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/05 16:41:55 controller.go:20: [PartyServer]: PartyServer Schedule worker 8 to node 0 
2022/06/05 16:41:55 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty0-cent-worker8-job8-tr-pred-task-stage
2022/06/05 16:41:55 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609/runtime_logs/pty0-cent-worker8-job8-tr-pred-task-stage
2022/06/05 16:41:55 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/05 16:41:55 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22114, ExecutorExecutorPort is [22115 22116 22117],
2022/06/05 16:41:55 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty0-cent-worker8-job8-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client0,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-0_20220603_205609/runtime_logs/pty0-cent-worker8-job8-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22114 \
--env MASTER_ADDR=127.0.0.1:22113 \
--env WORKER_ID=8 \
--env GROUP_ID=0 \
--env PARTY_ID=0 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/05 16:42:13 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/05 16:42:13 utils.go:198: [ExecuteCmd]: OutPut is  v8f2zc06hsk50xa7lbcj6yx1j
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/05 16:42:13 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
