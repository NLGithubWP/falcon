2022/06/03 20:56:28 global-const.go:244: Read user defined env var {IS_DEBUG: debug-off}
2022/06/03 20:56:28 global-const.go:241: Set env var to default {TEST_IMG_NAME: redis:5.0.3-alpine3.8}
2022/06/03 20:56:28 global-const.go:241: Set env var to default {FALCON_WORKER_IMAGE: falcon-dist-train:latest}
2022/06/03 20:56:28 global-const.go:244: Read user defined env var {COORD_SERVER_IP: 127.0.0.1}
2022/06/03 20:56:28 global-const.go:244: Read user defined env var {COORD_SERVER_PORT: 30004}
2022/06/03 20:56:28 global-const.go:244: Read user defined env var {PARTY_SERVER_IP: 127.0.0.1}
2022/06/03 20:56:28 global-const.go:244: Read user defined env var {PARTY_SERVER_NODE_PORT: 30007}
2022/06/03 20:56:28 global-const.go:244: Read user defined env var {PARTY_ID: 2}
2022/06/03 20:56:28 global-const.go:244: Read user defined env var {MPC_EXE_PATH: /opt/falcon/third_party/MP-SPDZ/semi-party.x}
2022/06/03 20:56:28 global-const.go:244: Read user defined env var {FL_ENGINE_PATH: /opt/falcon/build/src/executor/falcon}
2022/06/03 20:56:28 falcon_platform.go:181: common.MpcExecutorPortFileBasePath is /opt/falcon/third_party/MP-SPDZ/Programs/Public-Input/
2022/06/03 20:56:28 global-const.go:244: Read user defined env var {PARTY_SERVER_CLUSTER_IPS: 127.0.0.1}
2022/06/03 20:56:28 global-const.go:244: Read user defined env var {PARTY_SERVER_CLUSTER_LABEL: host}
2022/06/03 20:56:28 falcon_platform.go:196: common.PartyServerClusterIPs is [127.0.0.1]
2022/06/03 20:56:28 falcon_platform.go:197: common.PartyServerClusterIPs is [host]
2022/06/03 20:56:28 falcon_platform.go:359: Launch falcon_platform, Service is  partyserver
2022/06/03 20:56:28 run_partyserver.go:78: RunPartyServer: connecting to Coordinator 127.0.0.1:30004 to AddPort 30007
2022/06/03 20:56:28 run_partyserver.go:81: RunPartyServer: PartyServerAdd  127.0.0.1
2022/06/03 20:56:28 run_partyserver.go:88: [party server 2] listening on IP: 127.0.0.1, Port: 30007
2022/06/03 20:57:25 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30007
2022/06/03 20:57:25 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/03 20:57:25 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/03 20:57:25 controller.go:20: [PartyServer]: PartyServer Schedule worker 1 to node 0 
2022/06/03 20:57:25 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty2-cent-worker1-job1-tr-pred-task-stage
2022/06/03 20:57:25 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628/runtime_logs/pty2-cent-worker1-job1-tr-pred-task-stage
2022/06/03 20:57:25 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/03 20:57:25 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22012, ExecutorExecutorPort is [22013 22014 22015],
2022/06/03 20:57:25 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty2-cent-worker1-job1-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628/runtime_logs/pty2-cent-worker1-job1-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22012 \
--env MASTER_ADDR=127.0.0.1:22001 \
--env WORKER_ID=1 \
--env GROUP_ID=0 \
--env PARTY_ID=2 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/03 20:57:51 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/03 20:57:51 utils.go:198: [ExecuteCmd]: OutPut is  sn3x10yeb5z3kfha94l5nt01k
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/03 20:57:51 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/03 21:20:28 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30007
2022/06/03 21:20:28 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/03 21:20:28 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/03 21:20:28 controller.go:20: [PartyServer]: PartyServer Schedule worker 2 to node 0 
2022/06/03 21:20:28 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty2-cent-worker2-job2-tr-pred-task-stage
2022/06/03 21:20:28 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628/runtime_logs/pty2-cent-worker2-job2-tr-pred-task-stage
2022/06/03 21:20:28 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/03 21:20:28 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22028, ExecutorExecutorPort is [22029 22030 22031],
2022/06/03 21:20:28 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty2-cent-worker2-job2-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628/runtime_logs/pty2-cent-worker2-job2-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22028 \
--env MASTER_ADDR=127.0.0.1:22017 \
--env WORKER_ID=2 \
--env GROUP_ID=0 \
--env PARTY_ID=2 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/03 21:20:54 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/03 21:20:54 utils.go:198: [ExecuteCmd]: OutPut is  gtlboo5z2jfeefkdz3b88l20i
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/03 21:20:54 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/05 16:01:30 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30007
2022/06/05 16:01:30 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/05 16:01:30 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/05 16:01:30 controller.go:20: [PartyServer]: PartyServer Schedule worker 3 to node 0 
2022/06/05 16:01:30 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty2-cent-worker3-job3-tr-pred-task-stage
2022/06/05 16:01:30 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628/runtime_logs/pty2-cent-worker3-job3-tr-pred-task-stage
2022/06/05 16:01:30 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/05 16:01:30 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22044, ExecutorExecutorPort is [22045 22046 22047],
2022/06/05 16:01:30 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty2-cent-worker3-job3-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628/runtime_logs/pty2-cent-worker3-job3-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22044 \
--env MASTER_ADDR=127.0.0.1:22033 \
--env WORKER_ID=3 \
--env GROUP_ID=0 \
--env PARTY_ID=2 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/05 16:01:56 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/05 16:01:56 utils.go:198: [ExecuteCmd]: OutPut is  bbu1dgrexgt3ldytngw7bxtwi
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/05 16:01:56 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/05 16:09:00 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30007
2022/06/05 16:09:00 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/05 16:09:00 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/05 16:09:00 controller.go:20: [PartyServer]: PartyServer Schedule worker 4 to node 0 
2022/06/05 16:09:00 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty2-cent-worker4-job4-tr-pred-task-stage
2022/06/05 16:09:00 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628/runtime_logs/pty2-cent-worker4-job4-tr-pred-task-stage
2022/06/05 16:09:00 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/05 16:09:00 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22060, ExecutorExecutorPort is [22061 22062 22063],
2022/06/05 16:09:00 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty2-cent-worker4-job4-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628/runtime_logs/pty2-cent-worker4-job4-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22060 \
--env MASTER_ADDR=127.0.0.1:22049 \
--env WORKER_ID=4 \
--env GROUP_ID=0 \
--env PARTY_ID=2 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/05 16:09:25 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/05 16:09:25 utils.go:198: [ExecuteCmd]: OutPut is  j5o76h3yt68o1rfvxky9qssky
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/05 16:09:25 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/05 16:31:48 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30007
2022/06/05 16:31:48 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/05 16:31:48 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/05 16:31:48 controller.go:20: [PartyServer]: PartyServer Schedule worker 5 to node 0 
2022/06/05 16:31:48 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty2-cent-worker5-job5-tr-pred-task-stage
2022/06/05 16:31:48 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628/runtime_logs/pty2-cent-worker5-job5-tr-pred-task-stage
2022/06/05 16:31:48 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/05 16:31:48 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22076, ExecutorExecutorPort is [22077 22078 22079],
2022/06/05 16:31:48 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty2-cent-worker5-job5-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628/runtime_logs/pty2-cent-worker5-job5-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22076 \
--env MASTER_ADDR=127.0.0.1:22065 \
--env WORKER_ID=5 \
--env GROUP_ID=0 \
--env PARTY_ID=2 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/05 16:32:11 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/05 16:32:11 utils.go:198: [ExecuteCmd]: OutPut is  ln32ufwxs95kbtpx7o5y91wtb
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/05 16:32:11 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/05 16:35:19 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30007
2022/06/05 16:35:19 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/05 16:35:19 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/05 16:35:19 controller.go:20: [PartyServer]: PartyServer Schedule worker 6 to node 0 
2022/06/05 16:35:19 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty2-cent-worker6-job6-tr-pred-task-stage
2022/06/05 16:35:19 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628/runtime_logs/pty2-cent-worker6-job6-tr-pred-task-stage
2022/06/05 16:35:19 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/05 16:35:19 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22092, ExecutorExecutorPort is [22093 22094 22095],
2022/06/05 16:35:19 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty2-cent-worker6-job6-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628/runtime_logs/pty2-cent-worker6-job6-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22092 \
--env MASTER_ADDR=127.0.0.1:22081 \
--env WORKER_ID=6 \
--env GROUP_ID=0 \
--env PARTY_ID=2 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/05 16:35:37 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/05 16:35:37 utils.go:198: [ExecuteCmd]: OutPut is  wd7a2bgpr72gpcry8fjghojir
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/05 16:35:37 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/05 16:36:15 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30007
2022/06/05 16:36:15 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/05 16:36:15 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/05 16:36:15 controller.go:20: [PartyServer]: PartyServer Schedule worker 7 to node 0 
2022/06/05 16:36:15 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty2-cent-worker7-job7-tr-pred-task-stage
2022/06/05 16:36:15 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628/runtime_logs/pty2-cent-worker7-job7-tr-pred-task-stage
2022/06/05 16:36:15 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/05 16:36:15 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22108, ExecutorExecutorPort is [22109 22110 22111],
2022/06/05 16:36:15 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty2-cent-worker7-job7-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628/runtime_logs/pty2-cent-worker7-job7-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22108 \
--env MASTER_ADDR=127.0.0.1:22097 \
--env WORKER_ID=7 \
--env GROUP_ID=0 \
--env PARTY_ID=2 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/05 16:36:33 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/05 16:36:33 utils.go:198: [ExecuteCmd]: OutPut is  jf4o7t21mhanz2xtau59pv1on
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/05 16:36:33 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/05 16:41:55 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30007
2022/06/05 16:41:55 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/05 16:41:55 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/05 16:41:55 controller.go:20: [PartyServer]: PartyServer Schedule worker 8 to node 0 
2022/06/05 16:41:55 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty2-cent-worker8-job8-tr-pred-task-stage
2022/06/05 16:41:55 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628/runtime_logs/pty2-cent-worker8-job8-tr-pred-task-stage
2022/06/05 16:41:55 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/05 16:41:55 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22124, ExecutorExecutorPort is [22125 22126 22127],
2022/06/05 16:41:55 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty2-cent-worker8-job8-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client2,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-2_20220603_205628/runtime_logs/pty2-cent-worker8-job8-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22124 \
--env MASTER_ADDR=127.0.0.1:22113 \
--env WORKER_ID=8 \
--env GROUP_ID=0 \
--env PARTY_ID=2 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/05 16:42:12 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/05 16:42:12 utils.go:198: [ExecuteCmd]: OutPut is  jey5j12m6yky5a66c1pck6sd4
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/05 16:42:12 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
