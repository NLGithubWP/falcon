2022/06/03 20:56:17 global-const.go:244: Read user defined env var {IS_DEBUG: debug-off}
2022/06/03 20:56:17 global-const.go:241: Set env var to default {TEST_IMG_NAME: redis:5.0.3-alpine3.8}
2022/06/03 20:56:17 global-const.go:241: Set env var to default {FALCON_WORKER_IMAGE: falcon-dist-train:latest}
2022/06/03 20:56:17 global-const.go:244: Read user defined env var {COORD_SERVER_IP: 127.0.0.1}
2022/06/03 20:56:17 global-const.go:244: Read user defined env var {COORD_SERVER_PORT: 30004}
2022/06/03 20:56:17 global-const.go:244: Read user defined env var {PARTY_SERVER_IP: 127.0.0.1}
2022/06/03 20:56:17 global-const.go:244: Read user defined env var {PARTY_SERVER_NODE_PORT: 30006}
2022/06/03 20:56:17 global-const.go:244: Read user defined env var {PARTY_ID: 1}
2022/06/03 20:56:17 global-const.go:244: Read user defined env var {MPC_EXE_PATH: /opt/falcon/third_party/MP-SPDZ/semi-party.x}
2022/06/03 20:56:17 global-const.go:244: Read user defined env var {FL_ENGINE_PATH: /opt/falcon/build/src/executor/falcon}
2022/06/03 20:56:17 falcon_platform.go:181: common.MpcExecutorPortFileBasePath is /opt/falcon/third_party/MP-SPDZ/Programs/Public-Input/
2022/06/03 20:56:17 global-const.go:244: Read user defined env var {PARTY_SERVER_CLUSTER_IPS: 127.0.0.1}
2022/06/03 20:56:17 global-const.go:244: Read user defined env var {PARTY_SERVER_CLUSTER_LABEL: host}
2022/06/03 20:56:17 falcon_platform.go:196: common.PartyServerClusterIPs is [127.0.0.1]
2022/06/03 20:56:17 falcon_platform.go:197: common.PartyServerClusterIPs is [host]
2022/06/03 20:56:17 falcon_platform.go:359: Launch falcon_platform, Service is  partyserver
2022/06/03 20:56:17 run_partyserver.go:78: RunPartyServer: connecting to Coordinator 127.0.0.1:30004 to AddPort 30006
2022/06/03 20:56:17 run_partyserver.go:81: RunPartyServer: PartyServerAdd  127.0.0.1
2022/06/03 20:56:17 run_partyserver.go:88: [party server 1] listening on IP: 127.0.0.1, Port: 30006
2022/06/03 20:57:25 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30006
2022/06/03 20:57:25 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/03 20:57:25 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/03 20:57:25 controller.go:20: [PartyServer]: PartyServer Schedule worker 1 to node 0 
2022/06/03 20:57:25 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty1-cent-worker1-job1-tr-pred-task-stage
2022/06/03 20:57:25 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617/runtime_logs/pty1-cent-worker1-job1-tr-pred-task-stage
2022/06/03 20:57:25 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/03 20:57:25 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22007, ExecutorExecutorPort is [22008 22009 22010],
2022/06/03 20:57:25 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty1-cent-worker1-job1-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617/runtime_logs/pty1-cent-worker1-job1-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22007 \
--env MASTER_ADDR=127.0.0.1:22001 \
--env WORKER_ID=1 \
--env GROUP_ID=0 \
--env PARTY_ID=1 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/03 20:57:51 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/03 20:57:51 utils.go:198: [ExecuteCmd]: OutPut is  es39rf1bif3d8ku6tt9g2yb4v
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/03 20:57:51 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/03 21:20:28 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30006
2022/06/03 21:20:28 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/03 21:20:28 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/03 21:20:28 controller.go:20: [PartyServer]: PartyServer Schedule worker 2 to node 0 
2022/06/03 21:20:28 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty1-cent-worker2-job2-tr-pred-task-stage
2022/06/03 21:20:28 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617/runtime_logs/pty1-cent-worker2-job2-tr-pred-task-stage
2022/06/03 21:20:28 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/03 21:20:28 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22023, ExecutorExecutorPort is [22024 22025 22026],
2022/06/03 21:20:28 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty1-cent-worker2-job2-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617/runtime_logs/pty1-cent-worker2-job2-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22023 \
--env MASTER_ADDR=127.0.0.1:22017 \
--env WORKER_ID=2 \
--env GROUP_ID=0 \
--env PARTY_ID=1 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/03 21:20:54 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/03 21:20:54 utils.go:198: [ExecuteCmd]: OutPut is  nmzsxyky6mlkww3kvr4w0fw2d
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/03 21:20:54 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/05 16:01:30 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30006
2022/06/05 16:01:30 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/05 16:01:30 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/05 16:01:30 controller.go:20: [PartyServer]: PartyServer Schedule worker 3 to node 0 
2022/06/05 16:01:30 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty1-cent-worker3-job3-tr-pred-task-stage
2022/06/05 16:01:30 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617/runtime_logs/pty1-cent-worker3-job3-tr-pred-task-stage
2022/06/05 16:01:30 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/05 16:01:30 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22039, ExecutorExecutorPort is [22040 22041 22042],
2022/06/05 16:01:30 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty1-cent-worker3-job3-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617/runtime_logs/pty1-cent-worker3-job3-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22039 \
--env MASTER_ADDR=127.0.0.1:22033 \
--env WORKER_ID=3 \
--env GROUP_ID=0 \
--env PARTY_ID=1 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/05 16:01:56 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/05 16:01:56 utils.go:198: [ExecuteCmd]: OutPut is  6s5sfpuh6e8ii59dxgyd8o3ku
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/05 16:01:56 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/05 16:09:00 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30006
2022/06/05 16:09:00 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/05 16:09:00 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/05 16:09:00 controller.go:20: [PartyServer]: PartyServer Schedule worker 4 to node 0 
2022/06/05 16:09:00 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty1-cent-worker4-job4-tr-pred-task-stage
2022/06/05 16:09:00 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617/runtime_logs/pty1-cent-worker4-job4-tr-pred-task-stage
2022/06/05 16:09:00 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/05 16:09:00 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22055, ExecutorExecutorPort is [22056 22057 22058],
2022/06/05 16:09:00 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty1-cent-worker4-job4-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617/runtime_logs/pty1-cent-worker4-job4-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22055 \
--env MASTER_ADDR=127.0.0.1:22049 \
--env WORKER_ID=4 \
--env GROUP_ID=0 \
--env PARTY_ID=1 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/05 16:09:25 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/05 16:09:25 utils.go:198: [ExecuteCmd]: OutPut is  0pw5ypy7hm7c3ov8taa9w17tq
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/05 16:09:25 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/05 16:31:48 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30006
2022/06/05 16:31:48 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/05 16:31:48 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/05 16:31:48 controller.go:20: [PartyServer]: PartyServer Schedule worker 5 to node 0 
2022/06/05 16:31:48 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty1-cent-worker5-job5-tr-pred-task-stage
2022/06/05 16:31:48 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617/runtime_logs/pty1-cent-worker5-job5-tr-pred-task-stage
2022/06/05 16:31:48 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/05 16:31:48 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22071, ExecutorExecutorPort is [22072 22073 22074],
2022/06/05 16:31:48 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty1-cent-worker5-job5-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617/runtime_logs/pty1-cent-worker5-job5-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22071 \
--env MASTER_ADDR=127.0.0.1:22065 \
--env WORKER_ID=5 \
--env GROUP_ID=0 \
--env PARTY_ID=1 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/05 16:32:11 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/05 16:32:11 utils.go:198: [ExecuteCmd]: OutPut is  4hswv2tjyo509er0lyz65ttxl
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/05 16:32:11 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/05 16:35:19 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30006
2022/06/05 16:35:19 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/05 16:35:19 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/05 16:35:19 controller.go:20: [PartyServer]: PartyServer Schedule worker 6 to node 0 
2022/06/05 16:35:19 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty1-cent-worker6-job6-tr-pred-task-stage
2022/06/05 16:35:19 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617/runtime_logs/pty1-cent-worker6-job6-tr-pred-task-stage
2022/06/05 16:35:19 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/05 16:35:19 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22087, ExecutorExecutorPort is [22088 22089 22090],
2022/06/05 16:35:19 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty1-cent-worker6-job6-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617/runtime_logs/pty1-cent-worker6-job6-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22087 \
--env MASTER_ADDR=127.0.0.1:22081 \
--env WORKER_ID=6 \
--env GROUP_ID=0 \
--env PARTY_ID=1 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/05 16:35:37 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/05 16:35:37 utils.go:198: [ExecuteCmd]: OutPut is  wzgzbdmwvxhaie8xqt9e2vxhx
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/05 16:35:37 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/05 16:36:15 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30006
2022/06/05 16:36:15 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/05 16:36:15 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/05 16:36:15 controller.go:20: [PartyServer]: PartyServer Schedule worker 7 to node 0 
2022/06/05 16:36:15 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty1-cent-worker7-job7-tr-pred-task-stage
2022/06/05 16:36:15 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617/runtime_logs/pty1-cent-worker7-job7-tr-pred-task-stage
2022/06/05 16:36:15 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/05 16:36:15 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22103, ExecutorExecutorPort is [22104 22105 22106],
2022/06/05 16:36:15 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty1-cent-worker7-job7-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617/runtime_logs/pty1-cent-worker7-job7-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22103 \
--env MASTER_ADDR=127.0.0.1:22097 \
--env WORKER_ID=7 \
--env GROUP_ID=0 \
--env PARTY_ID=1 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/05 16:36:33 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/05 16:36:33 utils.go:198: [ExecuteCmd]: OutPut is  6mb336gn3ypemqykybyp7x4ox
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/05 16:36:33 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
2022/06/05 16:41:55 router.go:36: [PartyServer]: RunWorker registering partyServerPort to coord 30006
2022/06/05 16:41:55 controller.go:42: [PartyServer]: PartyServer setup workers, workerGroupNum =  1  workerPreGroup =  1 totalWorkers= 1 stageName= lime_pred_task_stage enableDistributedTrain= 0
2022/06/05 16:41:55 controller.go:49: [PartyServer]: PartyServer setup one worker for centralized training
2022/06/05 16:41:55 controller.go:20: [PartyServer]: PartyServer Schedule worker 8 to node 0 
2022/06/05 16:41:55 deploy-docker.go:96: [JobManager]: Current in docker, TrainWorker, svcName pty1-cent-worker8-job8-tr-pred-task-stage
2022/06/05 16:41:55 deploy-docker.go:109: [JobManager]: localTaskRuntimeLogs is  /opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617/runtime_logs/pty1-cent-worker8-job8-tr-pred-task-stage
2022/06/05 16:41:55 deploy-docker.go:140: [JobManager]: CentralizedWorker, map 2 ports to host
2022/06/05 16:41:55 deploy-docker.go:142: [JobManager]: CentralizedWorker, WorkerPort is 22119, ExecutorExecutorPort is [22120 22121 22122],
2022/06/05 16:41:55 utils.go:207: [ExecuteCmd]: /usr/bin/docker service create \
--name pty1-cent-worker8-job8-tr-pred-task-stage \
--network host \
--replicas 1 \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/dataPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/dataOutputPath \
--mount type=bind,source=/opt/falcon/data/dataset/bank_marketing_data/client1,destination=/modelPath \
--mount type=bind,source=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617,destination=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617 \
--env ENV=docker \
--env SERVICE_NAME=TrainWorker \
--env LOG_PATH=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617 \
--env TASK_DATA_PATH=/dataPath \
--env TASK_MODEL_PATH=/modelPath \
--env TASK_DATA_OUTPUT=/dataOutputPath \
--env RUN_TIME_LOGS=/opt/falcon/src/falcon_platform/falcon_logs/Party-1_20220603_205617/runtime_logs/pty1-cent-worker8-job8-tr-pred-task-stage \
--env WORKER_ADDR=127.0.0.1:22119 \
--env MASTER_ADDR=127.0.0.1:22113 \
--env WORKER_ID=8 \
--env GROUP_ID=0 \
--env PARTY_ID=1 \
--env DISTRIBUTED_ROLE=2 \
--env EXECUTOR_TYPE=TrainWorker \
--env MPC_EXE_PATH=/opt/falcon/third_party/MP-SPDZ/semi-party.x \
--env FL_ENGINE_PATH=/opt/falcon/build/src/executor/falcon \
--constraint node.labels.name==host \
--restart-condition on-failure falcon-dist-train:latest
2022/06/05 16:42:13 utils.go:197: [ExecuteCmd]: ErrorLog is  image falcon-dist-train:latest could not be accessed on a registry to record
its digest. Each node will access falcon-dist-train:latest independently,
possibly leading to different nodes running different
versions of the image.


2022/06/05 16:42:13 utils.go:198: [ExecuteCmd]: OutPut is  cdoylu6l0st5wo7z374qpip2j
overall progress: 0 out of 1 tasks
1/1:  
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 0 out of 1 tasks
overall progress: 1 out of 1 tasks
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 5 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 4 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 3 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 2 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Waiting 1 seconds to verify that tasks are stable...
verify: Service converged

2022/06/05 16:42:13 manager.go:110: [ResourceManager]: Release Resources, can not delete resources
